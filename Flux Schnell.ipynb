{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23333e3a-a287-4e23-9897-ee37bb755b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc92bdc-60f0-4b7e-90d7-120a54b1e776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905540e3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.0.1 --quiet\n",
    "!pip install diffusers==0.30.0 --quiet\n",
    "!pip install transformers==4.44.0 --quiet\n",
    "!pip install accelerate==0.30.0 --quiet\n",
    "!pip install sentencepiece==0.2.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691cbacd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88027d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a53ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile code/requirements.txt\n",
    "torch==2.0.1\n",
    "diffusers==0.30.0\n",
    "transformers==4.41.2\n",
    "accelerate==0.30.0\n",
    "sentencepiece==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9cac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile code/inference.py\n",
    "import base64\n",
    "import torch\n",
    "from io import BytesIO\n",
    "from diffusers import FluxPipeline\n",
    "\n",
    "\n",
    "def model_fn(model_dir, context=None):\n",
    "    pipe = FluxPipeline.from_pretrained(model_dir, torch_dtype=torch.bfloat16)\n",
    "    pipe.enable_sequential_cpu_offload()\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "\n",
    "def predict_fn(data, pipe):\n",
    "    # get prompt & parameters\n",
    "    prompt = data.pop(\"inputs\", data)\n",
    "    num_inference_steps = data.pop(\"num_inference_steps\", 4)\n",
    "    guidance_scale = data.pop(\"guidance_scale\", 1.5)\n",
    "    num_images_per_prompt = data.pop(\"num_images_per_prompt\", 1)\n",
    "\n",
    "    # Generate image\n",
    "    generated_images = pipe(\n",
    "        prompt,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "    )[\"images\"]\n",
    "\n",
    "    # create response\n",
    "    encoded_images = []\n",
    "    for image in generated_images:\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        encoded_images.append(base64.b64encode(buffered.getvalue()).decode())\n",
    "\n",
    "    # create response\n",
    "    return {\"generated_images\": encoded_images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7fc7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "HF_MODEL_ID = \"black-forest-labs/FLUX.1-schnell\"\n",
    "HF_TOKEN = \"Your HF Token\"\n",
    "\n",
    "# create model dir\n",
    "model_tar = Path(f\"Model-Flux-Schnell\")\n",
    "model_tar.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dad690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download snapshot\n",
    "snapshot_dir = snapshot_download(repo_id=HF_MODEL_ID, use_auth_token=HF_TOKEN, local_dir=model_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceef263-8dad-416a-991e-73922398872b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy code/ to model dir\n",
    "copy_tree(\"code/\", str(model_tar.joinpath(\"code\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878bf97e-a929-4d6c-83b9-4657846a2f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "\n",
    "model_tar = Path(f\"Model-Flux-Schnell\")\n",
    "\n",
    "# helper to create the model.tar.gz\n",
    "def compress(tar_dir=None,output_file=\"model.tar.gz\"):\n",
    "    parent_dir=os.getcwd()\n",
    "    os.chdir(tar_dir)\n",
    "    with tarfile.open(os.path.join(parent_dir, output_file), \"w:gz\") as tar:\n",
    "        for item in os.listdir(\".\"):\n",
    "          print(item)\n",
    "          tar.add(item, arcname=item)\n",
    "    os.chdir(parent_dir)\n",
    "\n",
    "compress(str(model_tar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9618fe-1641-4c54-8090-8acd1e1e2973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# upload model.tar.gz to s3\n",
    "s3_model_uri = S3Uploader.upload(local_path=\"model.tar.gz\", desired_s3_uri=f\"s3://{sess.default_bucket()}/flux-1-schnell\")\n",
    "\n",
    "print(f\"model uploaded to: {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fbbe53-617f-464a-8af3-6fef8472b8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_model_uri,\n",
    "   role=sagemaker.get_execution_role(),\n",
    "   transformers_version=\"4.37.0\",\n",
    "   pytorch_version=\"2.1.0\",\n",
    "   py_version='py310',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb445780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.4xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac33e2d-1793-4eae-878c-40c830080d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper decoder\n",
    "def decode_base64_image(image_string):\n",
    "  base64_image = base64.b64decode(image_string)\n",
    "  buffer = BytesIO(base64_image)\n",
    "  return Image.open(buffer)\n",
    "\n",
    "# display PIL images as grid\n",
    "def display_images(images=None,columns=3, width=100, height=100):\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e66d0-2001-4895-9773-30746b218150",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_per_prompt = 3\n",
    "prompt = \"Castle in Flower Field\"\n",
    "\n",
    "# run prediction\n",
    "response = predictor.predict(data={\n",
    "    \"inputs\": prompt,\n",
    "    \"num_images_per_prompt\": num_images_per_prompt,\n",
    "    \"num_inference_steps\": 4\n",
    "    }\n",
    ")\n",
    "\n",
    "# decode images\n",
    "decoded_images = [decode_base64_image(image) for image in response[\"generated_images\"]]\n",
    "\n",
    "# visualize generation\n",
    "display_images(decoded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21da21",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
